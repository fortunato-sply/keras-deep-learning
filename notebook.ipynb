{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import callbacks\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não pode encontrar o caminho especificado: 'caminho/para/fotos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\disrct\\Desktop\\keras\\keras-deep-learning\\notebook.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m   optimizer\u001b[39m=\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(), \u001b[39m# Adam e SGD são os optimizers mais utilizados\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m   loss\u001b[39m=\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m   metrics\u001b[39m=\u001b[39m[metrics\u001b[39m.\u001b[39mAccuracy(), metrics\u001b[39m.\u001b[39mPrecision()]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m dataGen \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mImageDataGenerator(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m   rescale \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m, \u001b[39m# redimensiona a escala de 0 a 255 para 0 a 1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m   shear_range \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m   validation_split \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m X_train \u001b[39m=\u001b[39m dataGen\u001b[39m.\u001b[39;49mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m   \u001b[39m'\u001b[39;49m\u001b[39mcaminho/para/fotos\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m   target_size \u001b[39m=\u001b[39;49m (\u001b[39m64\u001b[39;49m, \u001b[39m64\u001b[39;49m), \u001b[39m# tamanho desejado da imagem, redimensiona.\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m   batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m, \u001b[39m# passa a quantidade de imagens desejadas para treino\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m   class_mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcategorical\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m# binarico, categorico e de regressão.\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m   subset \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m X_test \u001b[39m=\u001b[39m dataGen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mcaminho/para/fotos\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m   target_size \u001b[39m=\u001b[39m (\u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m), \u001b[39m# tamanho desejado da imagem, redimensiona.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m   subset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m   X_train, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m   steps_per_epoch \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m, \u001b[39m# steps_per_epoch * batch_size == len(dataset) <- recomendado\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m   ]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/keras/keras-deep-learning/notebook.ipynb#W2sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m ) \n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:1649\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[39m        and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1649\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1650\u001b[0m         directory,\n\u001b[0;32m   1651\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1652\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1653\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1654\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[0;32m   1655\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1656\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1657\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1658\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1659\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1660\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1661\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1662\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1663\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1664\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[0;32m   1665\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1666\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1667\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1668\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema não pode encontrar o caminho especificado: 'caminho/para/fotos'"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(\n",
    "  32, (5, 5), # 32: numero de filtros e (5,5) é o shape do kernel que vai ser passado pela imagem, ela perde n-1 do tamanho em cada dimensão\n",
    "  input_shape = (64, 64, 3), # 64: tamanho da imagem, 3: diz que a imagem é RGB, se for preto e branco é 1\n",
    "  activation = 'relu'\n",
    "))\n",
    "\n",
    "model.add(layers.MaxPooling2D(\n",
    "  pool_size = (2, 2) # reduz o tamanho da imagem pela metade, passa um kernel 2x2 e retorna um valor 1x1\n",
    "))\n",
    "\n",
    "model.add(layers.Conv2D(\n",
    "  16, (5, 5),\n",
    "  input_shape = (30, 30, 3),  # 64 - 4 = 60 - 30 do MaxPooling = 30, 30\n",
    "  activation = 'relu'\n",
    "))\n",
    "\n",
    "model.add(layers.MaxPooling2D(\n",
    "  pool_size = (2, 2)\n",
    "))\n",
    "\n",
    "model.add(layers.Conv2D(\n",
    "  4, (5, 5),\n",
    "  input_shape = (13, 13, 3),\n",
    "  activation = 'relu'\n",
    "))\n",
    "\n",
    "model.add(layers.MaxPooling2D(\n",
    "  pool_size = (2, 2)\n",
    "))\n",
    "\n",
    "model.add(layers.Flatten()) # transforma a imagem de matriz 2d para vetor\n",
    "\n",
    "model.add(layers.Dense(256, # quantidade de neurônios\n",
    "  kernel_regularizer = regularizers.L2(1e-4), # penaliza pesos altos\n",
    "  kernel_initializer = initializers.RandomNormal(stddev=1), # inicialização dos pesos, inicia com desvio-padrão de 1, tem valores mais naturais\n",
    "  bias_initializer = initializers.Zeros() # inicia o bias como 0\n",
    "))\n",
    "\n",
    "model.add(layers.Dropout(0.2)) # diz que 20% dos neurônios serão desligados para evitar overfitting\n",
    "model.add(layers.Activation(activations.relu)) # filtra se o neurônio é importante (relu mantem os positivos e zera os negativos)\n",
    "\n",
    "model.add(layers.Dense(64,\n",
    "  kernel_regularizer = regularizers.L2(1e-4), \n",
    "  kernel_initializer = initializers.RandomNormal(stddev=1),\n",
    "  bias_initializer = initializers.Zeros() \n",
    "))\n",
    "\n",
    "model.add(layers.Activation(activations.relu))\n",
    "\n",
    "model.add(layers.BatchNormalization()) # normaliza os valores de saída da camada para reduzir overfitting, melhorar desempenho.\n",
    "\n",
    "model.add(layers.Dense(64,\n",
    "  kernel_regularizer = regularizers.L2(1e-4), \n",
    "  kernel_initializer = initializers.RandomNormal(stddev=1),\n",
    "  bias_initializer = initializers.Zeros() \n",
    "))\n",
    "\n",
    "model.add(layers.Activation(activations.relu))\n",
    "\n",
    "model.add(layers.Dense(2,\n",
    "  kernel_regularizer = regularizers.L2(1e-4), \n",
    "  kernel_initializer = initializers.RandomNormal(stddev=1),\n",
    "  bias_initializer = initializers.Zeros() \n",
    "))\n",
    "\n",
    "model.add(layers.Activation(activations.softmax))\n",
    "\n",
    "model.compile(\n",
    "  optimizer=optimizers.Adam(), # Adam e SGD são os optimizers mais utilizados\n",
    "  loss=losses.BinaryCrossentropy(),\n",
    "  metrics=[metrics.Accuracy(), metrics.Precision()]\n",
    ")\n",
    "\n",
    "dataGen = image.ImageDataGenerator(\n",
    "  rescale = 1.0/255, # redimensiona a escala de 0 a 255 para 0 a 1\n",
    "  shear_range = 0.2,\n",
    "  zoom_range = 0.2,\n",
    "  horizontal_flip = True,\n",
    "  vertical_flip = False,\n",
    "  validation_split = 0.2\n",
    ")\n",
    "\n",
    "X_train = dataGen.flow_from_directory(\n",
    "  'caminho/para/fotos',\n",
    "  target_size = (64, 64), # tamanho desejado da imagem, redimensiona.\n",
    "  batch_size = 32, # passa a quantidade de imagens desejadas para treino\n",
    "  class_mode = 'categorical', # binarico, categorico e de regressão.\n",
    "  subset = 'training'\n",
    ")\n",
    "\n",
    "X_test = dataGen.flow_from_directory(\n",
    "  'caminho/para/fotos',\n",
    "  target_size = (64, 64), # tamanho desejado da imagem, redimensiona.\n",
    "  batch_size = 32, # passa a quantidade de imagens desejadas para treino\n",
    "  class_mode = 'categorical', # binarico, categorico e de regressão.\n",
    "  subset = 'validation'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  X_train, \n",
    "  steps_per_epoch = 1000, # steps_per_epoch * batch_size == len(dataset) <- recomendado\n",
    "  epochs = 50,\n",
    "  validation_steps = 100, # steps_per_epoch / 10 <- recomendado\n",
    "  callbacks = [\n",
    "    callbacks.EarlyStopping(patience = 4),\n",
    "    callbacks.ModelCheckpoint(\n",
    "      filepath = 'model.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "    )\n",
    "  ]\n",
    ") \n",
    "\n",
    "model.save('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
