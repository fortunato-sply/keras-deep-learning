{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import callbacks\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19998 images belonging to 2 classes.\n",
      "Found 4998 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "196/624 [========>.....................] - ETA: 25s - loss: 0.8111 - accuracy: 0.0000e+00 - precision_15: 0.4995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\TiffImagePlugin.py:866: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 41s 65ms/step - loss: 0.7789 - accuracy: 0.0000e+00 - precision_15: 0.5309 - val_loss: 0.7418 - val_accuracy: 0.0000e+00 - val_precision_15: 0.5694\n",
      "Epoch 2/50\n",
      "  2/624 [..............................] - ETA: 40s - loss: 0.7921 - accuracy: 0.0000e+00 - precision_15: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 41s 65ms/step - loss: 0.7287 - accuracy: 0.0000e+00 - precision_15: 0.5631 - val_loss: 0.7134 - val_accuracy: 0.0000e+00 - val_precision_15: 0.5724\n",
      "Epoch 3/50\n",
      "624/624 [==============================] - 40s 65ms/step - loss: 0.7014 - accuracy: 0.0000e+00 - precision_15: 0.5945 - val_loss: 0.6906 - val_accuracy: 0.0000e+00 - val_precision_15: 0.6106\n",
      "Epoch 4/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.6694 - accuracy: 0.0000e+00 - precision_15: 0.6366 - val_loss: 0.6445 - val_accuracy: 0.0000e+00 - val_precision_15: 0.6538\n",
      "Epoch 5/50\n",
      "624/624 [==============================] - 41s 65ms/step - loss: 0.6401 - accuracy: 0.0000e+00 - precision_15: 0.6636 - val_loss: 0.6364 - val_accuracy: 0.0000e+00 - val_precision_15: 0.6701\n",
      "Epoch 6/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.6101 - accuracy: 0.0000e+00 - precision_15: 0.6906 - val_loss: 0.5883 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7078\n",
      "Epoch 7/50\n",
      "624/624 [==============================] - 41s 66ms/step - loss: 0.5899 - accuracy: 0.0000e+00 - precision_15: 0.7037 - val_loss: 0.5812 - val_accuracy: 0.0000e+00 - val_precision_15: 0.6989\n",
      "Epoch 8/50\n",
      "624/624 [==============================] - 41s 65ms/step - loss: 0.5724 - accuracy: 7.5007e-05 - precision_15: 0.7197 - val_loss: 0.5532 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7312\n",
      "Epoch 9/50\n",
      "624/624 [==============================] - 45s 72ms/step - loss: 0.5563 - accuracy: 1.0001e-04 - precision_15: 0.7331 - val_loss: 0.5466 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7436\n",
      "Epoch 10/50\n",
      "624/624 [==============================] - 47s 76ms/step - loss: 0.5440 - accuracy: 0.0000e+00 - precision_15: 0.7352 - val_loss: 0.5954 - val_accuracy: 0.0000e+00 - val_precision_15: 0.6870\n",
      "Epoch 11/50\n",
      "624/624 [==============================] - 43s 68ms/step - loss: 0.5272 - accuracy: 5.0005e-05 - precision_15: 0.7516 - val_loss: 0.5191 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7525\n",
      "Epoch 12/50\n",
      "624/624 [==============================] - 41s 65ms/step - loss: 0.5203 - accuracy: 7.5007e-05 - precision_15: 0.7556 - val_loss: 0.5264 - val_accuracy: 2.4802e-04 - val_precision_15: 0.7411\n",
      "Epoch 13/50\n",
      "624/624 [==============================] - 40s 65ms/step - loss: 0.5074 - accuracy: 2.2502e-04 - precision_15: 0.7623 - val_loss: 0.5113 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7515\n",
      "Epoch 14/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.5007 - accuracy: 2.7503e-04 - precision_15: 0.7668 - val_loss: 0.4950 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7669\n",
      "Epoch 15/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4957 - accuracy: 1.7502e-04 - precision_15: 0.7707 - val_loss: 0.4880 - val_accuracy: 2.4802e-04 - val_precision_15: 0.7589\n",
      "Epoch 16/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4859 - accuracy: 5.2505e-04 - precision_15: 0.7776 - val_loss: 0.4972 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7798\n",
      "Epoch 17/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4733 - accuracy: 5.0005e-04 - precision_15: 0.7877 - val_loss: 0.4763 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7897\n",
      "Epoch 18/50\n",
      "624/624 [==============================] - 40s 65ms/step - loss: 0.4721 - accuracy: 5.2505e-04 - precision_15: 0.7869 - val_loss: 0.4783 - val_accuracy: 7.4405e-04 - val_precision_15: 0.7808\n",
      "Epoch 19/50\n",
      "624/624 [==============================] - 41s 66ms/step - loss: 0.4633 - accuracy: 5.5006e-04 - precision_15: 0.7899 - val_loss: 0.4833 - val_accuracy: 2.4802e-04 - val_precision_15: 0.7837\n",
      "Epoch 20/50\n",
      "624/624 [==============================] - 40s 63ms/step - loss: 0.4619 - accuracy: 8.0008e-04 - precision_15: 0.7941 - val_loss: 0.4901 - val_accuracy: 4.9603e-04 - val_precision_15: 0.7753\n",
      "Epoch 21/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4539 - accuracy: 7.0007e-04 - precision_15: 0.7984 - val_loss: 0.4509 - val_accuracy: 4.9603e-04 - val_precision_15: 0.8001\n",
      "Epoch 22/50\n",
      "624/624 [==============================] - 40s 63ms/step - loss: 0.4492 - accuracy: 8.5008e-04 - precision_15: 0.8029 - val_loss: 0.4681 - val_accuracy: 0.0017 - val_precision_15: 0.7877\n",
      "Epoch 23/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4465 - accuracy: 9.5010e-04 - precision_15: 0.8033 - val_loss: 0.4723 - val_accuracy: 0.0000e+00 - val_precision_15: 0.7832\n",
      "Epoch 24/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4419 - accuracy: 0.0013 - precision_15: 0.8016 - val_loss: 0.4380 - val_accuracy: 9.9206e-04 - val_precision_15: 0.8061\n",
      "Epoch 25/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4373 - accuracy: 0.0011 - precision_15: 0.8092 - val_loss: 0.5135 - val_accuracy: 0.0015 - val_precision_15: 0.7649\n",
      "Epoch 26/50\n",
      "624/624 [==============================] - 42s 67ms/step - loss: 0.4376 - accuracy: 0.0014 - precision_15: 0.8072 - val_loss: 0.4750 - val_accuracy: 0.0015 - val_precision_15: 0.7788\n",
      "Epoch 27/50\n",
      "624/624 [==============================] - 43s 68ms/step - loss: 0.4269 - accuracy: 0.0022 - precision_15: 0.8117 - val_loss: 0.4952 - val_accuracy: 0.0025 - val_precision_15: 0.7703\n",
      "Epoch 28/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4286 - accuracy: 0.0019 - precision_15: 0.8133 - val_loss: 0.4489 - val_accuracy: 2.4802e-04 - val_precision_15: 0.7922\n",
      "Epoch 29/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4165 - accuracy: 0.0020 - precision_15: 0.8155 - val_loss: 0.4614 - val_accuracy: 2.4802e-04 - val_precision_15: 0.7867\n",
      "Epoch 30/50\n",
      "624/624 [==============================] - 39s 63ms/step - loss: 0.4151 - accuracy: 0.0021 - precision_15: 0.8210 - val_loss: 0.4485 - val_accuracy: 0.0015 - val_precision_15: 0.7927\n",
      "Epoch 31/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.4122 - accuracy: 0.0033 - precision_15: 0.8181 - val_loss: 0.4883 - val_accuracy: 2.4802e-04 - val_precision_15: 0.7703\n",
      "Epoch 32/50\n",
      "624/624 [==============================] - 40s 63ms/step - loss: 0.4087 - accuracy: 0.0029 - precision_15: 0.8224 - val_loss: 0.4219 - val_accuracy: 0.0030 - val_precision_15: 0.8180\n",
      "Epoch 33/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3994 - accuracy: 0.0038 - precision_15: 0.8303 - val_loss: 0.4503 - val_accuracy: 9.9206e-04 - val_precision_15: 0.8011\n",
      "Epoch 34/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3993 - accuracy: 0.0032 - precision_15: 0.8297 - val_loss: 0.4595 - val_accuracy: 0.0012 - val_precision_15: 0.7956\n",
      "Epoch 35/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3956 - accuracy: 0.0046 - precision_15: 0.8307 - val_loss: 0.4506 - val_accuracy: 0.0012 - val_precision_15: 0.7961\n",
      "Epoch 36/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3955 - accuracy: 0.0031 - precision_15: 0.8300 - val_loss: 0.4569 - val_accuracy: 0.0015 - val_precision_15: 0.8026\n",
      "Epoch 37/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3902 - accuracy: 0.0041 - precision_15: 0.8337 - val_loss: 0.4706 - val_accuracy: 0.0072 - val_precision_15: 0.7961\n",
      "Epoch 38/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3841 - accuracy: 0.0047 - precision_15: 0.8394 - val_loss: 0.4934 - val_accuracy: 9.9206e-04 - val_precision_15: 0.7743\n",
      "Epoch 39/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3819 - accuracy: 0.0050 - precision_15: 0.8386 - val_loss: 0.4780 - val_accuracy: 0.0025 - val_precision_15: 0.7932\n",
      "Epoch 40/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3795 - accuracy: 0.0050 - precision_15: 0.8382 - val_loss: 0.4308 - val_accuracy: 0.0012 - val_precision_15: 0.8026\n",
      "Epoch 41/50\n",
      "624/624 [==============================] - 40s 65ms/step - loss: 0.3718 - accuracy: 0.0049 - precision_15: 0.8427 - val_loss: 0.4539 - val_accuracy: 0.0027 - val_precision_15: 0.8001\n",
      "Epoch 42/50\n",
      "624/624 [==============================] - 39s 63ms/step - loss: 0.3771 - accuracy: 0.0049 - precision_15: 0.8406 - val_loss: 0.4468 - val_accuracy: 0.0025 - val_precision_15: 0.7981\n",
      "Epoch 43/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3714 - accuracy: 0.0066 - precision_15: 0.8410 - val_loss: 0.4573 - val_accuracy: 0.0037 - val_precision_15: 0.7981\n",
      "Epoch 44/50\n",
      "624/624 [==============================] - 40s 63ms/step - loss: 0.3657 - accuracy: 0.0074 - precision_15: 0.8450 - val_loss: 0.4937 - val_accuracy: 0.0064 - val_precision_15: 0.7857\n",
      "Epoch 45/50\n",
      "624/624 [==============================] - 45s 72ms/step - loss: 0.3592 - accuracy: 0.0084 - precision_15: 0.8503 - val_loss: 0.4732 - val_accuracy: 0.0050 - val_precision_15: 0.7971\n",
      "Epoch 46/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3509 - accuracy: 0.0087 - precision_15: 0.8551 - val_loss: 0.4771 - val_accuracy: 0.0037 - val_precision_15: 0.7917\n",
      "Epoch 47/50\n",
      "624/624 [==============================] - 41s 66ms/step - loss: 0.3526 - accuracy: 0.0099 - precision_15: 0.8536 - val_loss: 0.4790 - val_accuracy: 0.0074 - val_precision_15: 0.7922\n",
      "Epoch 48/50\n",
      "624/624 [==============================] - 154s 247ms/step - loss: 0.3474 - accuracy: 0.0100 - precision_15: 0.8586 - val_loss: 0.4710 - val_accuracy: 0.0060 - val_precision_15: 0.7956\n",
      "Epoch 49/50\n",
      "624/624 [==============================] - 40s 64ms/step - loss: 0.3435 - accuracy: 0.0108 - precision_15: 0.8582 - val_loss: 0.4916 - val_accuracy: 0.0082 - val_precision_15: 0.7941\n",
      "Epoch 50/50\n",
      "624/624 [==============================] - 39s 63ms/step - loss: 0.3413 - accuracy: 0.0121 - precision_15: 0.8597 - val_loss: 0.4418 - val_accuracy: 0.0027 - val_precision_15: 0.7981\n",
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(\n",
    "  32, (5, 5), # 32: numero de filtros e (5,5) é o shape do kernel que vai ser passado pela imagem, ela perde n-1 do tamanho em cada dimensão\n",
    "  input_shape = (64, 64, 3), # 64: tamanho da imagem, 3: diz que a imagem é RGB, se for preto e branco é 1\n",
    "  activation = 'relu'\n",
    "))\n",
    "\n",
    "model.add(layers.MaxPooling2D(\n",
    "  pool_size = (2, 2) # reduz o tamanho da imagem pela metade, passa um kernel 2x2 e retorna um valor 1x1\n",
    "))\n",
    "\n",
    "model.add(layers.Conv2D(\n",
    "  16, (5, 5),\n",
    "  input_shape = (30, 30, 3),  # 64 - 4 = 60 - 30 do MaxPooling = 30, 30\n",
    "  activation = 'relu'\n",
    "))\n",
    "\n",
    "model.add(layers.MaxPooling2D(\n",
    "  pool_size = (2, 2)\n",
    "))\n",
    "\n",
    "# model.add(layers.Conv2D(\n",
    "#   4, (5, 5),\n",
    "#   input_shape = (13, 13, 3),\n",
    "#   activation = 'relu'\n",
    "# ))\n",
    "\n",
    "# model.add(layers.MaxPooling2D(\n",
    "#   pool_size = (2, 2)\n",
    "# ))\n",
    "\n",
    "model.add(layers.Flatten()) # transforma a imagem de matriz 2d para vetor\n",
    "\n",
    "model.add(layers.Dense(256, # quantidade de neurônios\n",
    "  # kernel_regularizer = regularizers.L2(1e-4), # penaliza pesos altos\n",
    "  kernel_initializer = initializers.RandomNormal(stddev=1), # inicialização dos pesos, inicia com desvio-padrão de 1, tem valores mais naturais\n",
    "  # bias_initializer = initializers.Zeros() # inicia o bias como 0\n",
    "))\n",
    "\n",
    "model.add(layers.Activation(activations.relu)) # filtra se o neurônio é importante (relu mantem os positivos e zera os negativos)\n",
    "\n",
    "model.add(layers.Dense(64,\n",
    "  kernel_regularizer = regularizers.L1(1e-4), \n",
    "  # kernel_initializer = initializers.RandomNormal(stddev=1),\n",
    "  # bias_initializer = initializers.Zeros() \n",
    "))\n",
    "\n",
    "model.add(layers.Activation(activations.relu))\n",
    "\n",
    "model.add(layers.Dropout(0.15)) # diz que 20% dos neurônios serão desligados para evitar overfitting\n",
    "\n",
    "# model.add(layers.BatchNormalization()) # normaliza os valores de saída da camada para reduzir overfitting, melhorar desempenho.\n",
    "\n",
    "model.add(layers.Dense(64,\n",
    "  # kernel_regularizer = regularizers.L2(1e-4), \n",
    "  # kernel_initializer = initializers.RandomNormal(stddev=1),\n",
    "  # bias_initializer = initializers.Zeros() \n",
    "))\n",
    "\n",
    "model.add(layers.Activation(activations.relu))\n",
    "\n",
    "model.add(layers.Dense(2,\n",
    "  # kernel_regularizer = regularizers.L2(1e-4), \n",
    "  # kernel_initializer = initializers.RandomNormal(stddev=1),\n",
    "  # bias_initializer = initializers.Zeros() \n",
    "))\n",
    "\n",
    "model.add(layers.Activation(activations.softmax))\n",
    "\n",
    "model.compile(\n",
    "  optimizer=optimizers.Adam(), # Adam e SGD são os optimizers mais utilizados\n",
    "  loss=losses.BinaryCrossentropy(),\n",
    "  metrics=[metrics.Accuracy(), metrics.Precision()]\n",
    ")\n",
    "\n",
    "dataGen = image.ImageDataGenerator(\n",
    "  rescale = 1.0/255, # redimensiona a escala de 0 a 255 para 0 a 1\n",
    "  shear_range = 0.2,\n",
    "  zoom_range = 0.2,\n",
    "  horizontal_flip = True,\n",
    "  vertical_flip = False,\n",
    "  validation_split = 0.2\n",
    ")\n",
    "\n",
    "X_train = dataGen.flow_from_directory(\n",
    "  'PetImages',\n",
    "  target_size = (64, 64), # tamanho desejado da imagem, redimensiona.\n",
    "  batch_size = 32, # passa a quantidade de imagens desejadas para treino\n",
    "  class_mode = 'categorical', # binarico, categorico e de regressão.\n",
    "  subset = 'training'\n",
    ")\n",
    "\n",
    "X_test = dataGen.flow_from_directory(\n",
    "  'PetImages',\n",
    "  target_size = (64, 64), # tamanho desejado da imagem, redimensiona.\n",
    "  batch_size = 32, # passa a quantidade de imagens desejadas para treino\n",
    "  class_mode = 'categorical', # binarico, categorico e de regressão.\n",
    "  subset = 'validation'\n",
    ")\n",
    "\n",
    "total_data = 19998\n",
    "batch_size = 32\n",
    "\n",
    "model.fit(\n",
    "  X_train, \n",
    "  validation_data=X_test,\n",
    "  steps_per_epoch = total_data / batch_size, # steps_per_epoch * batch_size == len(dataset) <- recomendado\n",
    "  epochs = 50,\n",
    "  validation_steps = (total_data / batch_size) / 10, # steps_per_epoch / 10 <- recomendado\n",
    "  callbacks = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "      filepath = 'trained/model.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "    )\n",
    "  ]\n",
    ") \n",
    "\n",
    "model.save('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
